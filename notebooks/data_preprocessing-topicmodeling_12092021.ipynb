{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing and LDA Model Fitting for Iteration 3 of Fair Is:\n",
    "In this notebook I document preprocessing and LDA model fitting of my Primary Dataset for iteration 3 of the Fair Is project. \n",
    "For more information on the previous iterations of this project you can see my Data Managemant Plan and Methodologies Statement. \n",
    "\n",
    "To see how the Primary Dataset was created see Data Creation for Iteration 3 of Fair Is.\n",
    "\n",
    "This notebook is split between Preprocessing Steps and Model Fitting for our corpus of 308 papers.\n",
    "\n",
    "I conducted the following preprocessing steps:\n",
    "- **Tokenization**\n",
    "    - *ngrams*\n",
    "    - *bi-grams*\n",
    "    - *ngram verbs*\n",
    "    - *ngram nouns*\n",
    "    - *bigram nouns*\n",
    "- **Lematization**\n",
    "- **Creation of Dictionary and Document Term Matrices**\n",
    "\n",
    "I conducted the following Topic Modeling Steps: \n",
    "- **Fit model using LDA**\n",
    "- **Fitting other tipic CorEx (Correlation Explanation)**\n",
    "\n",
    "- **Further Normalization**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries and Packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import csv\n",
    "import nltk as nltk\n",
    "import gensim as gm\n",
    "import os\n",
    "import os.path\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/aster/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#in order to use the word_tokenize function we need the nltk punkt package. \n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accessing Clean Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = os.path.join('../data/processed_data/csv/cleaned_primary_data_12022021.csv')\n",
    "data = pd.read_csv(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>unfair items detection educational measurement</td>\n",
       "      <td>measurement professionals come agreement defi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>fairness academic course timetabling</td>\n",
       "      <td>consider problem creating fair course timetab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>safeguarding ecommerce advisor cheating behavi...</td>\n",
       "      <td>electronic marketplaces transaction buyers wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>decomposition maxmin fair curriculumbased cou...</td>\n",
       "      <td>propose decomposition maxmin fair curriculumb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>fair assignment indivisible objects ordinal pr...</td>\n",
       "      <td>consider discrete assignment problem agents e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X                                              title  \\\n",
       "0  1     unfair items detection educational measurement   \n",
       "1  2               fairness academic course timetabling   \n",
       "2  3  safeguarding ecommerce advisor cheating behavi...   \n",
       "3  4   decomposition maxmin fair curriculumbased cou...   \n",
       "4  5  fair assignment indivisible objects ordinal pr...   \n",
       "\n",
       "                                            abstract  \n",
       "0   measurement professionals come agreement defi...  \n",
       "1   consider problem creating fair course timetab...  \n",
       "2   electronic marketplaces transaction buyers wi...  \n",
       "3   propose decomposition maxmin fair curriculumb...  \n",
       "4   consider discrete assignment problem agents e...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just checking out data real quick\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['X', 'title', 'abstract'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing:\n",
    "\n",
    "Preprocessing is somewhat similar to cleaning, it describes the steps made to prepare data to be fit to a model. While the primary dataset is structured and cleaned it's still much closer to unstructured text than to something machine readable. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Tokenization* is the process of seperating meaningful strings of text into units called tokens. in Text Analysis, and Natural Language Processing more generally, models don't \"understand\" or \"read\" text in the way a human does. \n",
    "\n",
    "In tokenization i'm also thing about ngrams, or a sequence of tokens where *n* is some number --- A single token would be a unigram, two tokens would be a bigram, and so forth.\n",
    "\n",
    "Using bigrams allows us to take account of terms like \"machine learning\" rather than consider them seperate terms. \n",
    "\n",
    "So we will create new columns from our abstracts: \n",
    "\n",
    "- unigram tokens for titles\n",
    "- unigram tokens for abstracts\n",
    "- bigram tokens for titles\n",
    "- bigram tokens for abstracts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unigram tokens for titles:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following tookenization code was figured out by Professor Vicky Rampin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map = iterator (goes thru each row)\n",
    "# x = specific title that is being tokenized in the specific moment\n",
    "\n",
    "data['title_tokens'] = data['title'].map(lambda x: nltk.word_tokenize(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bigram tokens for titles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      [(unfair, items), (items, detection), (detecti...\n",
      "1      [(fairness, academic), (academic, course), (co...\n",
      "2      [(safeguarding, ecommerce), (ecommerce, adviso...\n",
      "3      [(decomposition, maxmin), (maxmin, fair), (fai...\n",
      "4      [(fair, assignment), (assignment, indivisible)...\n",
      "                             ...                        \n",
      "303    [(one, label), (label, one), (one, billion), (...\n",
      "304    [(reviewable, automated), (automated, decision...\n",
      "305    [(dangers, stochastic), (stochastic, parrots),...\n",
      "306    [(formalizing, trust), (trust, artificial), (a...\n",
      "307    [(tilt, gdpraligned), (gdpraligned, transparen...\n",
      "Name: title_bigrams, Length: 308, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data['title_bigrams'] = data['title_tokens'].apply(lambda row: list(nltk.bigrams(row)))\n",
    "print(data['title_bigrams'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### unigram tokens for abstracts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now let's apply this to abstracts:\n",
    "data['abstract_tokens'] = data['abstract'].map(lambda x: nltk.word_tokenize(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bigram tokens for abstracts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>title_tokens</th>\n",
       "      <th>title_bigrams</th>\n",
       "      <th>abstract_tokens</th>\n",
       "      <th>abstract_bigrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>unfair items detection educational measurement</td>\n",
       "      <td>measurement professionals come agreement defi...</td>\n",
       "      <td>[unfair, items, detection, educational, measur...</td>\n",
       "      <td>[(unfair, items), (items, detection), (detecti...</td>\n",
       "      <td>[measurement, professionals, come, agreement, ...</td>\n",
       "      <td>[(measurement, professionals), (professionals,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>fairness academic course timetabling</td>\n",
       "      <td>consider problem creating fair course timetab...</td>\n",
       "      <td>[fairness, academic, course, timetabling]</td>\n",
       "      <td>[(fairness, academic), (academic, course), (co...</td>\n",
       "      <td>[consider, problem, creating, fair, course, ti...</td>\n",
       "      <td>[(consider, problem), (problem, creating), (cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>safeguarding ecommerce advisor cheating behavi...</td>\n",
       "      <td>electronic marketplaces transaction buyers wi...</td>\n",
       "      <td>[safeguarding, ecommerce, advisor, cheating, b...</td>\n",
       "      <td>[(safeguarding, ecommerce), (ecommerce, adviso...</td>\n",
       "      <td>[electronic, marketplaces, transaction, buyers...</td>\n",
       "      <td>[(electronic, marketplaces), (marketplaces, tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>decomposition maxmin fair curriculumbased cou...</td>\n",
       "      <td>propose decomposition maxmin fair curriculumb...</td>\n",
       "      <td>[decomposition, maxmin, fair, curriculumbased,...</td>\n",
       "      <td>[(decomposition, maxmin), (maxmin, fair), (fai...</td>\n",
       "      <td>[propose, decomposition, maxmin, fair, curricu...</td>\n",
       "      <td>[(propose, decomposition), (decomposition, max...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>fair assignment indivisible objects ordinal pr...</td>\n",
       "      <td>consider discrete assignment problem agents e...</td>\n",
       "      <td>[fair, assignment, indivisible, objects, ordin...</td>\n",
       "      <td>[(fair, assignment), (assignment, indivisible)...</td>\n",
       "      <td>[consider, discrete, assignment, problem, agen...</td>\n",
       "      <td>[(consider, discrete), (discrete, assignment),...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X                                              title  \\\n",
       "0  1     unfair items detection educational measurement   \n",
       "1  2               fairness academic course timetabling   \n",
       "2  3  safeguarding ecommerce advisor cheating behavi...   \n",
       "3  4   decomposition maxmin fair curriculumbased cou...   \n",
       "4  5  fair assignment indivisible objects ordinal pr...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0   measurement professionals come agreement defi...   \n",
       "1   consider problem creating fair course timetab...   \n",
       "2   electronic marketplaces transaction buyers wi...   \n",
       "3   propose decomposition maxmin fair curriculumb...   \n",
       "4   consider discrete assignment problem agents e...   \n",
       "\n",
       "                                        title_tokens  \\\n",
       "0  [unfair, items, detection, educational, measur...   \n",
       "1          [fairness, academic, course, timetabling]   \n",
       "2  [safeguarding, ecommerce, advisor, cheating, b...   \n",
       "3  [decomposition, maxmin, fair, curriculumbased,...   \n",
       "4  [fair, assignment, indivisible, objects, ordin...   \n",
       "\n",
       "                                       title_bigrams  \\\n",
       "0  [(unfair, items), (items, detection), (detecti...   \n",
       "1  [(fairness, academic), (academic, course), (co...   \n",
       "2  [(safeguarding, ecommerce), (ecommerce, adviso...   \n",
       "3  [(decomposition, maxmin), (maxmin, fair), (fai...   \n",
       "4  [(fair, assignment), (assignment, indivisible)...   \n",
       "\n",
       "                                     abstract_tokens  \\\n",
       "0  [measurement, professionals, come, agreement, ...   \n",
       "1  [consider, problem, creating, fair, course, ti...   \n",
       "2  [electronic, marketplaces, transaction, buyers...   \n",
       "3  [propose, decomposition, maxmin, fair, curricu...   \n",
       "4  [consider, discrete, assignment, problem, agen...   \n",
       "\n",
       "                                    abstract_bigrams  \n",
       "0  [(measurement, professionals), (professionals,...  \n",
       "1  [(consider, problem), (problem, creating), (cr...  \n",
       "2  [(electronic, marketplaces), (marketplaces, tr...  \n",
       "3  [(propose, decomposition), (decomposition, max...  \n",
       "4  [(consider, discrete), (discrete, assignment),...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['abstract_bigrams'] = data['abstract_tokens'].apply(lambda row: list(nltk.bigrams(row)))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#abstract_tokens_pos --> create\n",
    "#abstract_bigrams_pos --> create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parts of Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/aster/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#in order to use the nltk pos_tag function need averaged_perceptron_tagger\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying parts of speech tagging with unigram tokens\n",
    "data['title_tokens_pos'] = data['title_tokens'].apply(lambda row: list(nltk.pos_tag(row)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [(unfair, JJ), (items, NNS), (detection, VBP),...\n",
       "1    [(fairness, JJ), (academic, JJ), (course, NN),...\n",
       "2    [(safeguarding, VBG), (ecommerce, NN), (adviso...\n",
       "3    [(decomposition, NN), (maxmin, NN), (fair, NN)...\n",
       "4    [(fair, JJ), (assignment, NN), (indivisible, J...\n",
       "Name: title_tokens_pos, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking to see if it worked\n",
    "data['title_tokens_pos'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#does this also work with bigrams? \n",
    "data['title_bigrams_pos'] = data['title_tokens_pos'].apply(lambda row: list(nltk.bigrams(row)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now parts of speech tagging for abstracts bigrams\n",
    "data['abstract_tokens_pos'] = data['abstract_tokens'].apply(lambda row: list(nltk.pos_tag(row)))\n",
    "data['abstract_bigrams_pos'] = data['abstract_tokens_pos'].apply(lambda row: list(nltk.bigrams(row)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>title_tokens</th>\n",
       "      <th>title_bigrams</th>\n",
       "      <th>abstract_tokens</th>\n",
       "      <th>abstract_bigrams</th>\n",
       "      <th>title_tokens_pos</th>\n",
       "      <th>title_bigrams_pos</th>\n",
       "      <th>abstract_tokens_pos</th>\n",
       "      <th>abstract_bigrams_pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>unfair items detection educational measurement</td>\n",
       "      <td>measurement professionals come agreement defi...</td>\n",
       "      <td>[unfair, items, detection, educational, measur...</td>\n",
       "      <td>[(unfair, items), (items, detection), (detecti...</td>\n",
       "      <td>[measurement, professionals, come, agreement, ...</td>\n",
       "      <td>[(measurement, professionals), (professionals,...</td>\n",
       "      <td>[(unfair, JJ), (items, NNS), (detection, VBP),...</td>\n",
       "      <td>[((unfair, JJ), (items, NNS)), ((items, NNS), ...</td>\n",
       "      <td>[(measurement, NN), (professionals, NNS), (com...</td>\n",
       "      <td>[((measurement, NN), (professionals, NNS)), ((...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>fairness academic course timetabling</td>\n",
       "      <td>consider problem creating fair course timetab...</td>\n",
       "      <td>[fairness, academic, course, timetabling]</td>\n",
       "      <td>[(fairness, academic), (academic, course), (co...</td>\n",
       "      <td>[consider, problem, creating, fair, course, ti...</td>\n",
       "      <td>[(consider, problem), (problem, creating), (cr...</td>\n",
       "      <td>[(fairness, JJ), (academic, JJ), (course, NN),...</td>\n",
       "      <td>[((fairness, JJ), (academic, JJ)), ((academic,...</td>\n",
       "      <td>[(consider, VB), (problem, NN), (creating, VBG...</td>\n",
       "      <td>[((consider, VB), (problem, NN)), ((problem, N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>safeguarding ecommerce advisor cheating behavi...</td>\n",
       "      <td>electronic marketplaces transaction buyers wi...</td>\n",
       "      <td>[safeguarding, ecommerce, advisor, cheating, b...</td>\n",
       "      <td>[(safeguarding, ecommerce), (ecommerce, adviso...</td>\n",
       "      <td>[electronic, marketplaces, transaction, buyers...</td>\n",
       "      <td>[(electronic, marketplaces), (marketplaces, tr...</td>\n",
       "      <td>[(safeguarding, VBG), (ecommerce, NN), (adviso...</td>\n",
       "      <td>[((safeguarding, VBG), (ecommerce, NN)), ((eco...</td>\n",
       "      <td>[(electronic, JJ), (marketplaces, NNS), (trans...</td>\n",
       "      <td>[((electronic, JJ), (marketplaces, NNS)), ((ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>decomposition maxmin fair curriculumbased cou...</td>\n",
       "      <td>propose decomposition maxmin fair curriculumb...</td>\n",
       "      <td>[decomposition, maxmin, fair, curriculumbased,...</td>\n",
       "      <td>[(decomposition, maxmin), (maxmin, fair), (fai...</td>\n",
       "      <td>[propose, decomposition, maxmin, fair, curricu...</td>\n",
       "      <td>[(propose, decomposition), (decomposition, max...</td>\n",
       "      <td>[(decomposition, NN), (maxmin, NN), (fair, NN)...</td>\n",
       "      <td>[((decomposition, NN), (maxmin, NN)), ((maxmin...</td>\n",
       "      <td>[(propose, JJ), (decomposition, NN), (maxmin, ...</td>\n",
       "      <td>[((propose, JJ), (decomposition, NN)), ((decom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>fair assignment indivisible objects ordinal pr...</td>\n",
       "      <td>consider discrete assignment problem agents e...</td>\n",
       "      <td>[fair, assignment, indivisible, objects, ordin...</td>\n",
       "      <td>[(fair, assignment), (assignment, indivisible)...</td>\n",
       "      <td>[consider, discrete, assignment, problem, agen...</td>\n",
       "      <td>[(consider, discrete), (discrete, assignment),...</td>\n",
       "      <td>[(fair, JJ), (assignment, NN), (indivisible, J...</td>\n",
       "      <td>[((fair, JJ), (assignment, NN)), ((assignment,...</td>\n",
       "      <td>[(consider, VB), (discrete, JJ), (assignment, ...</td>\n",
       "      <td>[((consider, VB), (discrete, JJ)), ((discrete,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X                                              title  \\\n",
       "0  1     unfair items detection educational measurement   \n",
       "1  2               fairness academic course timetabling   \n",
       "2  3  safeguarding ecommerce advisor cheating behavi...   \n",
       "3  4   decomposition maxmin fair curriculumbased cou...   \n",
       "4  5  fair assignment indivisible objects ordinal pr...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0   measurement professionals come agreement defi...   \n",
       "1   consider problem creating fair course timetab...   \n",
       "2   electronic marketplaces transaction buyers wi...   \n",
       "3   propose decomposition maxmin fair curriculumb...   \n",
       "4   consider discrete assignment problem agents e...   \n",
       "\n",
       "                                        title_tokens  \\\n",
       "0  [unfair, items, detection, educational, measur...   \n",
       "1          [fairness, academic, course, timetabling]   \n",
       "2  [safeguarding, ecommerce, advisor, cheating, b...   \n",
       "3  [decomposition, maxmin, fair, curriculumbased,...   \n",
       "4  [fair, assignment, indivisible, objects, ordin...   \n",
       "\n",
       "                                       title_bigrams  \\\n",
       "0  [(unfair, items), (items, detection), (detecti...   \n",
       "1  [(fairness, academic), (academic, course), (co...   \n",
       "2  [(safeguarding, ecommerce), (ecommerce, adviso...   \n",
       "3  [(decomposition, maxmin), (maxmin, fair), (fai...   \n",
       "4  [(fair, assignment), (assignment, indivisible)...   \n",
       "\n",
       "                                     abstract_tokens  \\\n",
       "0  [measurement, professionals, come, agreement, ...   \n",
       "1  [consider, problem, creating, fair, course, ti...   \n",
       "2  [electronic, marketplaces, transaction, buyers...   \n",
       "3  [propose, decomposition, maxmin, fair, curricu...   \n",
       "4  [consider, discrete, assignment, problem, agen...   \n",
       "\n",
       "                                    abstract_bigrams  \\\n",
       "0  [(measurement, professionals), (professionals,...   \n",
       "1  [(consider, problem), (problem, creating), (cr...   \n",
       "2  [(electronic, marketplaces), (marketplaces, tr...   \n",
       "3  [(propose, decomposition), (decomposition, max...   \n",
       "4  [(consider, discrete), (discrete, assignment),...   \n",
       "\n",
       "                                    title_tokens_pos  \\\n",
       "0  [(unfair, JJ), (items, NNS), (detection, VBP),...   \n",
       "1  [(fairness, JJ), (academic, JJ), (course, NN),...   \n",
       "2  [(safeguarding, VBG), (ecommerce, NN), (adviso...   \n",
       "3  [(decomposition, NN), (maxmin, NN), (fair, NN)...   \n",
       "4  [(fair, JJ), (assignment, NN), (indivisible, J...   \n",
       "\n",
       "                                   title_bigrams_pos  \\\n",
       "0  [((unfair, JJ), (items, NNS)), ((items, NNS), ...   \n",
       "1  [((fairness, JJ), (academic, JJ)), ((academic,...   \n",
       "2  [((safeguarding, VBG), (ecommerce, NN)), ((eco...   \n",
       "3  [((decomposition, NN), (maxmin, NN)), ((maxmin...   \n",
       "4  [((fair, JJ), (assignment, NN)), ((assignment,...   \n",
       "\n",
       "                                 abstract_tokens_pos  \\\n",
       "0  [(measurement, NN), (professionals, NNS), (com...   \n",
       "1  [(consider, VB), (problem, NN), (creating, VBG...   \n",
       "2  [(electronic, JJ), (marketplaces, NNS), (trans...   \n",
       "3  [(propose, JJ), (decomposition, NN), (maxmin, ...   \n",
       "4  [(consider, VB), (discrete, JJ), (assignment, ...   \n",
       "\n",
       "                                abstract_bigrams_pos  \n",
       "0  [((measurement, NN), (professionals, NNS)), ((...  \n",
       "1  [((consider, VB), (problem, NN)), ((problem, N...  \n",
       "2  [((electronic, JJ), (marketplaces, NNS)), ((ma...  \n",
       "3  [((propose, JJ), (decomposition, NN)), ((decom...  \n",
       "4  [((consider, VB), (discrete, JJ)), ((discrete,...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking to see if this worked:\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in order to use lemmatization we need to use\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(alist):\n",
    "    for text in alist:\n",
    "        for w in text:\n",
    "    #for w in range(len(text)):\n",
    "        #for w in row:\n",
    "            return lem.lemmatize(w)\n",
    "            #return lem.lemmatize(w, pos='n')\n",
    "        #.apply(lambda x: lemmatize_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['title_lemmatized']= data['title_tokens'].map(lambda x: lemmatize_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>title_tokens</th>\n",
       "      <th>title_bigrams</th>\n",
       "      <th>abstract_tokens</th>\n",
       "      <th>abstract_bigrams</th>\n",
       "      <th>title_tokens_pos</th>\n",
       "      <th>title_bigrams_pos</th>\n",
       "      <th>abstract_tokens_pos</th>\n",
       "      <th>abstract_bigrams_pos</th>\n",
       "      <th>title_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>unfair items detection educational measurement</td>\n",
       "      <td>measurement professionals come agreement defi...</td>\n",
       "      <td>[unfair, items, detection, educational, measur...</td>\n",
       "      <td>[(unfair, items), (items, detection), (detecti...</td>\n",
       "      <td>[measurement, professionals, come, agreement, ...</td>\n",
       "      <td>[(measurement, professionals), (professionals,...</td>\n",
       "      <td>[(unfair, JJ), (items, NNS), (detection, VBP),...</td>\n",
       "      <td>[((unfair, JJ), (items, NNS)), ((items, NNS), ...</td>\n",
       "      <td>[(measurement, NN), (professionals, NNS), (com...</td>\n",
       "      <td>[((measurement, NN), (professionals, NNS)), ((...</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>fairness academic course timetabling</td>\n",
       "      <td>consider problem creating fair course timetab...</td>\n",
       "      <td>[fairness, academic, course, timetabling]</td>\n",
       "      <td>[(fairness, academic), (academic, course), (co...</td>\n",
       "      <td>[consider, problem, creating, fair, course, ti...</td>\n",
       "      <td>[(consider, problem), (problem, creating), (cr...</td>\n",
       "      <td>[(fairness, JJ), (academic, JJ), (course, NN),...</td>\n",
       "      <td>[((fairness, JJ), (academic, JJ)), ((academic,...</td>\n",
       "      <td>[(consider, VB), (problem, NN), (creating, VBG...</td>\n",
       "      <td>[((consider, VB), (problem, NN)), ((problem, N...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>safeguarding ecommerce advisor cheating behavi...</td>\n",
       "      <td>electronic marketplaces transaction buyers wi...</td>\n",
       "      <td>[safeguarding, ecommerce, advisor, cheating, b...</td>\n",
       "      <td>[(safeguarding, ecommerce), (ecommerce, adviso...</td>\n",
       "      <td>[electronic, marketplaces, transaction, buyers...</td>\n",
       "      <td>[(electronic, marketplaces), (marketplaces, tr...</td>\n",
       "      <td>[(safeguarding, VBG), (ecommerce, NN), (adviso...</td>\n",
       "      <td>[((safeguarding, VBG), (ecommerce, NN)), ((eco...</td>\n",
       "      <td>[(electronic, JJ), (marketplaces, NNS), (trans...</td>\n",
       "      <td>[((electronic, JJ), (marketplaces, NNS)), ((ma...</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>decomposition maxmin fair curriculumbased cou...</td>\n",
       "      <td>propose decomposition maxmin fair curriculumb...</td>\n",
       "      <td>[decomposition, maxmin, fair, curriculumbased,...</td>\n",
       "      <td>[(decomposition, maxmin), (maxmin, fair), (fai...</td>\n",
       "      <td>[propose, decomposition, maxmin, fair, curricu...</td>\n",
       "      <td>[(propose, decomposition), (decomposition, max...</td>\n",
       "      <td>[(decomposition, NN), (maxmin, NN), (fair, NN)...</td>\n",
       "      <td>[((decomposition, NN), (maxmin, NN)), ((maxmin...</td>\n",
       "      <td>[(propose, JJ), (decomposition, NN), (maxmin, ...</td>\n",
       "      <td>[((propose, JJ), (decomposition, NN)), ((decom...</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>fair assignment indivisible objects ordinal pr...</td>\n",
       "      <td>consider discrete assignment problem agents e...</td>\n",
       "      <td>[fair, assignment, indivisible, objects, ordin...</td>\n",
       "      <td>[(fair, assignment), (assignment, indivisible)...</td>\n",
       "      <td>[consider, discrete, assignment, problem, agen...</td>\n",
       "      <td>[(consider, discrete), (discrete, assignment),...</td>\n",
       "      <td>[(fair, JJ), (assignment, NN), (indivisible, J...</td>\n",
       "      <td>[((fair, JJ), (assignment, NN)), ((assignment,...</td>\n",
       "      <td>[(consider, VB), (discrete, JJ), (assignment, ...</td>\n",
       "      <td>[((consider, VB), (discrete, JJ)), ((discrete,...</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   X                                              title  \\\n",
       "0  1     unfair items detection educational measurement   \n",
       "1  2               fairness academic course timetabling   \n",
       "2  3  safeguarding ecommerce advisor cheating behavi...   \n",
       "3  4   decomposition maxmin fair curriculumbased cou...   \n",
       "4  5  fair assignment indivisible objects ordinal pr...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0   measurement professionals come agreement defi...   \n",
       "1   consider problem creating fair course timetab...   \n",
       "2   electronic marketplaces transaction buyers wi...   \n",
       "3   propose decomposition maxmin fair curriculumb...   \n",
       "4   consider discrete assignment problem agents e...   \n",
       "\n",
       "                                        title_tokens  \\\n",
       "0  [unfair, items, detection, educational, measur...   \n",
       "1          [fairness, academic, course, timetabling]   \n",
       "2  [safeguarding, ecommerce, advisor, cheating, b...   \n",
       "3  [decomposition, maxmin, fair, curriculumbased,...   \n",
       "4  [fair, assignment, indivisible, objects, ordin...   \n",
       "\n",
       "                                       title_bigrams  \\\n",
       "0  [(unfair, items), (items, detection), (detecti...   \n",
       "1  [(fairness, academic), (academic, course), (co...   \n",
       "2  [(safeguarding, ecommerce), (ecommerce, adviso...   \n",
       "3  [(decomposition, maxmin), (maxmin, fair), (fai...   \n",
       "4  [(fair, assignment), (assignment, indivisible)...   \n",
       "\n",
       "                                     abstract_tokens  \\\n",
       "0  [measurement, professionals, come, agreement, ...   \n",
       "1  [consider, problem, creating, fair, course, ti...   \n",
       "2  [electronic, marketplaces, transaction, buyers...   \n",
       "3  [propose, decomposition, maxmin, fair, curricu...   \n",
       "4  [consider, discrete, assignment, problem, agen...   \n",
       "\n",
       "                                    abstract_bigrams  \\\n",
       "0  [(measurement, professionals), (professionals,...   \n",
       "1  [(consider, problem), (problem, creating), (cr...   \n",
       "2  [(electronic, marketplaces), (marketplaces, tr...   \n",
       "3  [(propose, decomposition), (decomposition, max...   \n",
       "4  [(consider, discrete), (discrete, assignment),...   \n",
       "\n",
       "                                    title_tokens_pos  \\\n",
       "0  [(unfair, JJ), (items, NNS), (detection, VBP),...   \n",
       "1  [(fairness, JJ), (academic, JJ), (course, NN),...   \n",
       "2  [(safeguarding, VBG), (ecommerce, NN), (adviso...   \n",
       "3  [(decomposition, NN), (maxmin, NN), (fair, NN)...   \n",
       "4  [(fair, JJ), (assignment, NN), (indivisible, J...   \n",
       "\n",
       "                                   title_bigrams_pos  \\\n",
       "0  [((unfair, JJ), (items, NNS)), ((items, NNS), ...   \n",
       "1  [((fairness, JJ), (academic, JJ)), ((academic,...   \n",
       "2  [((safeguarding, VBG), (ecommerce, NN)), ((eco...   \n",
       "3  [((decomposition, NN), (maxmin, NN)), ((maxmin...   \n",
       "4  [((fair, JJ), (assignment, NN)), ((assignment,...   \n",
       "\n",
       "                                 abstract_tokens_pos  \\\n",
       "0  [(measurement, NN), (professionals, NNS), (com...   \n",
       "1  [(consider, VB), (problem, NN), (creating, VBG...   \n",
       "2  [(electronic, JJ), (marketplaces, NNS), (trans...   \n",
       "3  [(propose, JJ), (decomposition, NN), (maxmin, ...   \n",
       "4  [(consider, VB), (discrete, JJ), (assignment, ...   \n",
       "\n",
       "                                abstract_bigrams_pos title_lemmatized  \n",
       "0  [((measurement, NN), (professionals, NNS)), ((...                u  \n",
       "1  [((consider, VB), (problem, NN)), ((problem, N...                f  \n",
       "2  [((electronic, JJ), (marketplaces, NNS)), ((ma...                s  \n",
       "3  [((propose, JJ), (decomposition, NN)), ((decom...                d  \n",
       "4  [((consider, VB), (discrete, JJ)), ((discrete,...                f  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Notes from Nick:\n",
    "#see if you can isolate a single term, using basic lemmatizer\n",
    "#lower the ocmplexity adn zero down on a smaller version for the problem. try it with one and then go from there.\n",
    "#think about arrays\n",
    "#try it out with one less complex example\n",
    "\n",
    "#array of array is an issue\n",
    "\n",
    "# tyringing it unfair \n",
    "# trying it [unfair, educational, measurement]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_y(text):\n",
    "    for x in text:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemy(text):\n",
    "    for w in text:\n",
    "        print(lem.lemmatize(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['libraries', 'corpora', 'fairness', 'adversarial', 'mitigating', 'recommendation'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "library\n",
      "corpus\n",
      "fairness\n",
      "adversarial\n",
      "mitigating\n",
      "recommendation\n"
     ]
    }
   ],
   "source": [
    "lemy(words)\n",
    "#func_y(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unfair\n",
      "item\n",
      "detection\n",
      "educational\n",
      "measurement\n",
      "fairness\n",
      "academic\n",
      "course\n",
      "timetabling\n",
      "safeguarding\n",
      "ecommerce\n",
      "advisor\n",
      "cheating\n",
      "behavior\n",
      "towards\n",
      "robust\n",
      "trust\n",
      "model\n",
      "handling\n",
      "unfair\n",
      "rating\n",
      "decomposition\n",
      "maxmin\n",
      "fair\n",
      "curriculumbased\n",
      "course\n",
      "timetabling\n",
      "problem\n",
      "fair\n",
      "assignment\n",
      "indivisible\n",
      "object\n",
      "ordinal\n",
      "preference\n",
      "online\n",
      "fair\n",
      "division\n",
      "analysing\n",
      "food\n",
      "bank\n",
      "problem\n",
      "relation\n",
      "accuracy\n",
      "fairness\n",
      "binary\n",
      "classification\n",
      "fair\n",
      "task\n",
      "allocation\n",
      "transportation\n",
      "efficiency\n",
      "sequenceability\n",
      "fair\n",
      "division\n",
      "indivisible\n",
      "good\n",
      "additive\n",
      "preference\n",
      "fairness\n",
      "program\n",
      "property\n",
      "fair\n",
      "division\n",
      "via\n",
      "social\n",
      "comparison\n",
      "balancing\n",
      "lexicographic\n",
      "fairness\n",
      "utilitarian\n",
      "objective\n",
      "application\n",
      "kidney\n",
      "exchange\n",
      "fairjudge\n",
      "trustworthy\n",
      "user\n",
      "prediction\n",
      "rating\n",
      "platform\n",
      "beyond\n",
      "parity\n",
      "fairness\n",
      "objective\n",
      "collaborative\n",
      "filtering\n",
      "new\n",
      "fairness\n",
      "metric\n",
      "recommendation\n",
      "embrace\n",
      "difference\n",
      "impossibility\n",
      "fairness\n",
      "generalized\n",
      "impossibility\n",
      "result\n",
      "decision\n",
      "networked\n",
      "fairness\n",
      "cake\n",
      "cutting\n",
      "fairnessaware\n",
      "machine\n",
      "learning\n",
      "perspective\n",
      "fairness\n",
      "testing\n",
      "testing\n",
      "software\n",
      "discrimination\n",
      "formalizing\n",
      "fairness\n",
      "prediction\n",
      "machine\n",
      "learning\n",
      "twostage\n",
      "algorithm\n",
      "fairnessaware\n",
      "machine\n",
      "learning\n",
      "multiwinner\n",
      "voting\n",
      "fairness\n",
      "constraint\n",
      "groupwise\n",
      "maximin\n",
      "fair\n",
      "allocation\n",
      "indivisible\n",
      "good\n",
      "fairness\n",
      "supervised\n",
      "learning\n",
      "information\n",
      "theoretic\n",
      "approach\n",
      "value\n",
      "alignment\n",
      "fair\n",
      "play\n",
      "right\n",
      "service\n",
      "robot\n",
      "reinforcement\n",
      "learning\n",
      "fair\n",
      "dynamic\n",
      "pricing\n",
      "deep\n",
      "bayesian\n",
      "trust\n",
      "dominant\n",
      "fair\n",
      "incentive\n",
      "mechanism\n",
      "crowd\n",
      "fair\n",
      "division\n",
      "cardinality\n",
      "constraint\n",
      "claudette\n",
      "automated\n",
      "detector\n",
      "potentially\n",
      "unfair\n",
      "clause\n",
      "online\n",
      "term\n",
      "service\n",
      "causal\n",
      "reasoning\n",
      "algorithmic\n",
      "fairness\n",
      "pooling\n",
      "causal\n",
      "model\n",
      "counterfactual\n",
      "fairness\n",
      "via\n",
      "causal\n",
      "judgement\n",
      "aggregation\n",
      "causal\n",
      "intervention\n",
      "fairness\n",
      "lecture\n",
      "note\n",
      "fair\n",
      "division\n",
      "fairness\n",
      "behind\n",
      "veil\n",
      "ignorance\n",
      "welfare\n",
      "analysis\n",
      "automated\n",
      "decision\n",
      "making\n",
      "comparing\n",
      "fairness\n",
      "criterion\n",
      "based\n",
      "social\n",
      "outcome\n",
      "applied\n",
      "fairness\n",
      "classification\n",
      "fairness\n",
      "constraint\n",
      "metaalgorithm\n",
      "provable\n",
      "guarantee\n",
      "automated\n",
      "directed\n",
      "fairness\n",
      "testing\n",
      "fairly\n",
      "allocating\n",
      "many\n",
      "good\n",
      "query\n",
      "efficiency\n",
      "sequenceability\n",
      "dealoptimality\n",
      "fair\n",
      "division\n",
      "indivisible\n",
      "good\n",
      "optimization\n",
      "nondifferentiable\n",
      "constraint\n",
      "application\n",
      "fairness\n",
      "recall\n",
      "churn\n",
      "goal\n",
      "fair\n",
      "lending\n",
      "need\n",
      "explainable\n",
      "model\n",
      "responsible\n",
      "recommendation\n",
      "fairnessaware\n",
      "classification\n",
      "criterion\n",
      "convexity\n",
      "bound\n",
      "active\n",
      "fairness\n",
      "algorithmic\n",
      "decision\n",
      "making\n",
      "counterfactually\n",
      "fair\n",
      "prediction\n",
      "using\n",
      "multiple\n",
      "causal\n",
      "model\n",
      "can\n",
      "everyday\n",
      "ai\n",
      "ethical\n",
      "fairness\n",
      "machine\n",
      "learning\n",
      "algorithm\n",
      "ai\n",
      "fairness\n",
      "extensible\n",
      "toolkit\n",
      "detecting\n",
      "understanding\n",
      "mitigating\n",
      "unwanted\n",
      "algorithmic\n",
      "bias\n",
      "general\n",
      "framework\n",
      "fair\n",
      "regression\n",
      "fairness\n",
      "critically\n",
      "reframing\n",
      "fairness\n",
      "nash\n",
      "welfare\n",
      "product\n",
      "crowdsourcing\n",
      "fairness\n",
      "diversity\n",
      "budget\n",
      "constraint\n",
      "fairmod\n",
      "making\n",
      "predictive\n",
      "model\n",
      "discrimination\n",
      "aware\n",
      "fairness\n",
      "definition\n",
      "fare\n",
      "examining\n",
      "public\n",
      "attitude\n",
      "towards\n",
      "algorithmic\n",
      "definition\n",
      "fairness\n",
      "aequitas\n",
      "bias\n",
      "fairness\n",
      "audit\n",
      "toolkit\n",
      "bayesian\n",
      "modeling\n",
      "intersectional\n",
      "fairness\n",
      "variance\n",
      "bias\n",
      "intersectionality\n",
      "multiple\n",
      "group\n",
      "fairness\n",
      "expectation\n",
      "constraint\n",
      "year\n",
      "test\n",
      "unfairness\n",
      "lesson\n",
      "machine\n",
      "learning\n",
      "ai\n",
      "fairness\n",
      "people\n",
      "disability\n",
      "point\n",
      "view\n",
      "probabilistic\n",
      "verification\n",
      "fairness\n",
      "property\n",
      "via\n",
      "concentration\n",
      "learning\n",
      "controllable\n",
      "fair\n",
      "representation\n",
      "putting\n",
      "fairness\n",
      "principle\n",
      "practice\n",
      "challenge\n",
      "metric\n",
      "improvement\n",
      "noisetolerant\n",
      "fair\n",
      "classification\n",
      "stable\n",
      "fair\n",
      "classification\n",
      "capuchin\n",
      "causal\n",
      "database\n",
      "repair\n",
      "algorithmic\n",
      "fairness\n",
      "fairness\n",
      "recommendation\n",
      "ranking\n",
      "pairwise\n",
      "comparison\n",
      "longterm\n",
      "impact\n",
      "algorithmic\n",
      "decision\n",
      "policy\n",
      "effort\n",
      "unfairness\n",
      "feature\n",
      "segregation\n",
      "social\n",
      "learning\n",
      "leveling\n",
      "playing\n",
      "field\n",
      "fairness\n",
      "ai\n",
      "versus\n",
      "human\n",
      "game\n",
      "benchmark\n",
      "fair\n",
      "classification\n",
      "social\n",
      "welfare\n",
      "fairness\n",
      "machine\n",
      "learning\n",
      "tractable\n",
      "model\n",
      "compositional\n",
      "fairness\n",
      "constraint\n",
      "graph\n",
      "embeddings\n",
      "fairness\n",
      "missing\n",
      "value\n",
      "achieving\n",
      "fairness\n",
      "determining\n",
      "medicaid\n",
      "eligibility\n",
      "fairgroup\n",
      "construction\n",
      "towards\n",
      "fair\n",
      "privacypreserving\n",
      "federated\n",
      "deep\n",
      "model\n",
      "flexibly\n",
      "fair\n",
      "representation\n",
      "learning\n",
      "disentanglement\n",
      "fair\n",
      "division\n",
      "without\n",
      "disparate\n",
      "impact\n",
      "learning\n",
      "fair\n",
      "naive\n",
      "bayes\n",
      "classifier\n",
      "discovering\n",
      "eliminating\n",
      "discrimination\n",
      "pattern\n",
      "farm\n",
      "fair\n",
      "reward\n",
      "mechanism\n",
      "information\n",
      "aggregation\n",
      "spontaneous\n",
      "localized\n",
      "setting\n",
      "extended\n",
      "version\n",
      "inherent\n",
      "tradeoff\n",
      "learning\n",
      "fair\n",
      "representation\n",
      "fairness\n",
      "criterion\n",
      "lens\n",
      "directed\n",
      "acyclic\n",
      "graphical\n",
      "model\n",
      "reinforcement\n",
      "learning\n",
      "fairness\n",
      "constraint\n",
      "resource\n",
      "distribution\n",
      "humanrobot\n",
      "team\n",
      "fairnas\n",
      "rethinking\n",
      "evaluation\n",
      "fairness\n",
      "weight\n",
      "sharing\n",
      "neural\n",
      "architecture\n",
      "search\n",
      "toward\n",
      "fairness\n",
      "ai\n",
      "people\n",
      "disability\n",
      "research\n",
      "roadmap\n",
      "fairst\n",
      "equitable\n",
      "spatial\n",
      "temporal\n",
      "demand\n",
      "prediction\n",
      "new\n",
      "mobility\n",
      "system\n",
      "fairnessenhancing\n",
      "intervention\n",
      "stream\n",
      "classification\n",
      "faht\n",
      "adaptive\n",
      "fairnessaware\n",
      "decision\n",
      "tree\n",
      "classifier\n",
      "fairness\n",
      "reinforcement\n",
      "learning\n",
      "point\n",
      "fairness\n",
      "disability\n",
      "ai\n",
      "complexity\n",
      "justice\n",
      "fairness\n",
      "deep\n",
      "learning\n",
      "computational\n",
      "perspective\n",
      "fairnessaware\n",
      "process\n",
      "mining\n",
      "quantifying\n",
      "inframarginality\n",
      "tradeoff\n",
      "group\n",
      "fairness\n",
      "avoiding\n",
      "resentment\n",
      "via\n",
      "monotonic\n",
      "fairness\n",
      "fat\n",
      "forensics\n",
      "python\n",
      "toolbox\n",
      "algorithmic\n",
      "fairness\n",
      "accountability\n",
      "transparency\n",
      "causal\n",
      "modeling\n",
      "fairness\n",
      "dynamical\n",
      "system\n",
      "groupbased\n",
      "fair\n",
      "learning\n",
      "lead\n",
      "counterintuitive\n",
      "prediction\n",
      "impact\n",
      "data\n",
      "preparation\n",
      "fairness\n",
      "software\n",
      "system\n",
      "fairness\n",
      "clustering\n",
      "multiple\n",
      "sensitive\n",
      "attribute\n",
      "conditional\n",
      "learning\n",
      "fair\n",
      "representation\n",
      "empirical\n",
      "study\n",
      "learning\n",
      "fairness\n",
      "metric\n",
      "compas\n",
      "data\n",
      "human\n",
      "supervision\n",
      "gender\n",
      "matter\n",
      "towards\n",
      "fairness\n",
      "dialogue\n",
      "system\n",
      "preventing\n",
      "adversarial\n",
      "use\n",
      "datasets\n",
      "fair\n",
      "coreset\n",
      "construction\n",
      "pcfairness\n",
      "unified\n",
      "framework\n",
      "measuring\n",
      "causalitybased\n",
      "fairness\n",
      "learning\n",
      "fairness\n",
      "multiagent\n",
      "system\n",
      "auditing\n",
      "achieving\n",
      "intersectional\n",
      "fairness\n",
      "classification\n",
      "problem\n",
      "humanintheloop\n",
      "framework\n",
      "construct\n",
      "contextdependent\n",
      "mathematical\n",
      "formulation\n",
      "fairness\n",
      "fairnessaware\n",
      "neural\n",
      "reyni\n",
      "minimization\n",
      "continuous\n",
      "feature\n",
      "fair\n",
      "adversarial\n",
      "gradient\n",
      "tree\n",
      "boosting\n",
      "fair\n",
      "data\n",
      "adaptation\n",
      "quantile\n",
      "preservation\n",
      "fairness\n",
      "equality\n",
      "effort\n",
      "online\n",
      "fair\n",
      "division\n",
      "survey\n",
      "towards\n",
      "fair\n",
      "protocol\n",
      "workflow\n",
      "openpredict\n",
      "case\n",
      "study\n",
      "greedy\n",
      "algorithm\n",
      "fair\n",
      "division\n",
      "mixed\n",
      "manna\n",
      "fair\n",
      "eye\n",
      "others\n",
      "fair\n",
      "dart\n",
      "eliminating\n",
      "unfair\n",
      "advantage\n",
      "differentiable\n",
      "architecture\n",
      "search\n",
      "legal\n",
      "compatibility\n",
      "fairness\n",
      "definition\n",
      "recovering\n",
      "biased\n",
      "data\n",
      "can\n",
      "fairness\n",
      "constraint\n",
      "improve\n",
      "accuracy\n",
      "group\n",
      "fairness\n",
      "bandit\n",
      "arm\n",
      "selection\n",
      "ltlf\n",
      "synthesis\n",
      "fairness\n",
      "stability\n",
      "assumption\n",
      "fair\n",
      "contextual\n",
      "multiarmed\n",
      "bandit\n",
      "theory\n",
      "experiment\n",
      "balancing\n",
      "tradeoff\n",
      "profit\n",
      "fairness\n",
      "rideshare\n",
      "platform\n",
      "highdemand\n",
      "hour\n",
      "stochastic\n",
      "fairness\n",
      "languagetheoretic\n",
      "fairness\n",
      "planning\n",
      "nondeterministic\n",
      "domain\n",
      "leveraging\n",
      "semisupervised\n",
      "learning\n",
      "fairness\n",
      "using\n",
      "neural\n",
      "network\n",
      "measuring\n",
      "nonexpert\n",
      "comprehension\n",
      "machine\n",
      "learning\n",
      "fairness\n",
      "metric\n",
      "consequentialism\n",
      "fairness\n",
      "fairness\n",
      "learningbased\n",
      "sequential\n",
      "decision\n",
      "algorithm\n",
      "survey\n",
      "fair\n",
      "transfer\n",
      "multiple\n",
      "style\n",
      "attribute\n",
      "text\n",
      "adequate\n",
      "fair\n",
      "explanation\n",
      "algorithmic\n",
      "fairness\n",
      "nonideal\n",
      "perspective\n",
      "algorithmic\n",
      "fairness\n",
      "fae\n",
      "fairnessaware\n",
      "ensemble\n",
      "framework\n",
      "joint\n",
      "optimization\n",
      "ai\n",
      "fairness\n",
      "utility\n",
      "humancentered\n",
      "approach\n",
      "fair\n",
      "correlation\n",
      "clustering\n",
      "fair\n",
      "correlation\n",
      "clustering\n",
      "convex\n",
      "fairness\n",
      "constrained\n",
      "model\n",
      "using\n",
      "causal\n",
      "effect\n",
      "estimator\n",
      "learning\n",
      "individually\n",
      "fair\n",
      "classifier\n",
      "pathspecific\n",
      "causaleffect\n",
      "constraint\n",
      "fair\n",
      "prediction\n",
      "endogenous\n",
      "behavior\n",
      "designing\n",
      "fair\n",
      "ai\n",
      "managing\n",
      "employee\n",
      "organization\n",
      "review\n",
      "critique\n",
      "design\n",
      "agenda\n",
      "learning\n",
      "fairnessaware\n",
      "relational\n",
      "structure\n",
      "learning\n",
      "certified\n",
      "individually\n",
      "fair\n",
      "representation\n",
      "fairrec\n",
      "twosided\n",
      "fairness\n",
      "personalized\n",
      "recommendation\n",
      "twosided\n",
      "platform\n",
      "counterfactual\n",
      "fairness\n",
      "removing\n",
      "direct\n",
      "effect\n",
      "regularization\n",
      "chexclusion\n",
      "fairness\n",
      "gap\n",
      "deep\n",
      "chest\n",
      "xray\n",
      "classifier\n",
      "evidencebased\n",
      "explanation\n",
      "promote\n",
      "fairness\n",
      "ai\n",
      "system\n",
      "getting\n",
      "fairness\n",
      "right\n",
      "towards\n",
      "toolbox\n",
      "practitioner\n",
      "finding\n",
      "fair\n",
      "efficient\n",
      "allocation\n",
      "valuation\n",
      "dont\n",
      "add\n",
      "best\n",
      "practice\n",
      "implementing\n",
      "fair\n",
      "vocabulary\n",
      "ontology\n",
      "web\n",
      "game\n",
      "fairness\n",
      "interpretability\n",
      "fairness\n",
      "bioinspired\n",
      "optimization\n",
      "research\n",
      "prescription\n",
      "methodological\n",
      "guideline\n",
      "comparing\n",
      "metaheuristics\n",
      "hierarchically\n",
      "fair\n",
      "federated\n",
      "learning\n",
      "jealousyfreeness\n",
      "common\n",
      "property\n",
      "fair\n",
      "division\n",
      "mixed\n",
      "manna\n",
      "ensuring\n",
      "fairness\n",
      "prior\n",
      "probability\n",
      "shift\n",
      "fair\n",
      "division\n",
      "computer\n",
      "scientist\n",
      "perspective\n",
      "fairness\n",
      "automated\n",
      "bridging\n",
      "gap\n",
      "eu\n",
      "nondiscrimination\n",
      "law\n",
      "ai\n",
      "reputation\n",
      "agent\n",
      "prompting\n",
      "fair\n",
      "review\n",
      "gig\n",
      "market\n",
      "ethical\n",
      "adversary\n",
      "towards\n",
      "mitigating\n",
      "unfairness\n",
      "adversarial\n",
      "machine\n",
      "learning\n",
      "statistical\n",
      "equity\n",
      "fairness\n",
      "classification\n",
      "objective\n",
      "fair\n",
      "outlier\n",
      "detection\n",
      "gender\n",
      "slope\n",
      "counterfactual\n",
      "fairness\n",
      "computer\n",
      "vision\n",
      "model\n",
      "attribute\n",
      "manipulation\n",
      "opportunistic\n",
      "multiaspect\n",
      "fairness\n",
      "personalized\n",
      "reranking\n",
      "fair\n",
      "classification\n",
      "via\n",
      "unconstrained\n",
      "optimization\n",
      "whats\n",
      "sex\n",
      "got\n",
      "fair\n",
      "machine\n",
      "learning\n",
      "fairnessaware\n",
      "explainable\n",
      "recommendation\n",
      "knowledge\n",
      "graph\n",
      "quest\n",
      "fair\n",
      "schedule\n",
      "young\n",
      "physicist\n",
      "tournament\n",
      "fair\n",
      "classification\n",
      "noisy\n",
      "protected\n",
      "attribute\n",
      "framework\n",
      "provable\n",
      "guarantee\n",
      "deepfair\n",
      "deep\n",
      "learning\n",
      "improving\n",
      "fairness\n",
      "recommender\n",
      "system\n",
      "balancing\n",
      "fairness\n",
      "efficiency\n",
      "optimization\n",
      "model\n",
      "system\n",
      "integrate\n",
      "fairness\n",
      "transparently\n",
      "industry\n",
      "approach\n",
      "fair\n",
      "influence\n",
      "maximization\n",
      "welfare\n",
      "optimization\n",
      "approach\n",
      "causal\n",
      "intersectionality\n",
      "fair\n",
      "ranking\n",
      "fair\n",
      "kmeans\n",
      "clustering\n",
      "probabilistic\n",
      "fair\n",
      "clustering\n",
      "verifying\n",
      "individual\n",
      "fairness\n",
      "machine\n",
      "learning\n",
      "model\n",
      "machine\n",
      "learning\n",
      "pipeline\n",
      "provenance\n",
      "reproducibility\n",
      "fair\n",
      "data\n",
      "principle\n",
      "framework\n",
      "fairness\n",
      "twosided\n",
      "marketplace\n",
      "applicability\n",
      "ml\n",
      "fairness\n",
      "notion\n",
      "fairness\n",
      "machine\n",
      "learning\n",
      "false\n",
      "positive\n",
      "rate\n",
      "equality\n",
      "measure\n",
      "fairness\n",
      "algorithmic\n",
      "fairness\n",
      "education\n",
      "causal\n",
      "linear\n",
      "model\n",
      "quantify\n",
      "edge\n",
      "unfairness\n",
      "unfair\n",
      "edge\n",
      "prioritization\n",
      "discrimination\n",
      "removal\n",
      "impossibility\n",
      "theorem\n",
      "machine\n",
      "fairness\n",
      "causal\n",
      "perspective\n",
      "fair\n",
      "algorithm\n",
      "multiagent\n",
      "multiarmed\n",
      "bandit\n",
      "algorithmic\n",
      "stability\n",
      "fair\n",
      "allocation\n",
      "indivisible\n",
      "good\n",
      "among\n",
      "two\n",
      "agent\n",
      "fairnessaware\n",
      "online\n",
      "personalization\n",
      "predictability\n",
      "fairness\n",
      "social\n",
      "sensing\n",
      "online\n",
      "task\n",
      "scheduling\n",
      "fog\n",
      "computing\n",
      "multiresource\n",
      "fairness\n",
      "machine\n",
      "learning\n",
      "fairness\n",
      "justice\n",
      "system\n",
      "base\n",
      "rate\n",
      "false\n",
      "positive\n",
      "false\n",
      "negative\n",
      "memory\n",
      "network\n",
      "consumer\n",
      "protectionunfairness\n",
      "exposed\n",
      "lift\n",
      "scalable\n",
      "framework\n",
      "measuring\n",
      "fairness\n",
      "ml\n",
      "application\n",
      "learning\n",
      "fair\n",
      "policy\n",
      "multiobjective\n",
      "deep\n",
      "reinforcement\n",
      "learning\n",
      "average\n",
      "discounted\n",
      "reward\n",
      "improving\n",
      "fair\n",
      "prediction\n",
      "using\n",
      "variational\n",
      "inference\n",
      "causal\n",
      "model\n",
      "adversarial\n",
      "learning\n",
      "counterfactual\n",
      "fairness\n",
      "fairxgboost\n",
      "fairnessaware\n",
      "classification\n",
      "xgboost\n",
      "fairness\n",
      "eye\n",
      "data\n",
      "certifying\n",
      "machinelearning\n",
      "model\n",
      "general\n",
      "framework\n",
      "fairness\n",
      "multistakeholder\n",
      "recommendation\n",
      "winner\n",
      "dynamic\n",
      "lottery\n",
      "multigroup\n",
      "fairnessaware\n",
      "recommendation\n",
      "identification\n",
      "fair\n",
      "auditor\n",
      "evaluate\n",
      "recommender\n",
      "system\n",
      "based\n",
      "novel\n",
      "noncomparative\n",
      "fairness\n",
      "notion\n",
      "addressing\n",
      "fairness\n",
      "classification\n",
      "modelagnostic\n",
      "multiobjective\n",
      "algorithm\n",
      "fairness\n",
      "fake\n",
      "data\n",
      "legal\n",
      "ai\n",
      "fairness\n",
      "matter\n",
      "datadriven\n",
      "framework\n",
      "towards\n",
      "fair\n",
      "high\n",
      "performing\n",
      "facial\n",
      "recognition\n",
      "system\n",
      "active\n",
      "fairness\n",
      "instead\n",
      "unawareness\n",
      "neither\n",
      "private\n",
      "fair\n",
      "impact\n",
      "data\n",
      "imbalance\n",
      "utility\n",
      "fairness\n",
      "differential\n",
      "privacy\n",
      "justicia\n",
      "stochastic\n",
      "sat\n",
      "approach\n",
      "formally\n",
      "verify\n",
      "fairness\n",
      "group\n",
      "fairness\n",
      "probabilistic\n",
      "modeling\n",
      "latent\n",
      "fair\n",
      "decision\n",
      "understanding\n",
      "fairness\n",
      "gender\n",
      "classification\n",
      "algorithm\n",
      "across\n",
      "genderrace\n",
      "group\n",
      "differentially\n",
      "private\n",
      "fair\n",
      "deep\n",
      "learning\n",
      "lagrangian\n",
      "dual\n",
      "approach\n",
      "fair\n",
      "metalearning\n",
      "fewshot\n",
      "classification\n",
      "towards\n",
      "measure\n",
      "individual\n",
      "fairness\n",
      "deep\n",
      "learning\n",
      "fairness\n",
      "diversity\n",
      "ranking\n",
      "twosided\n",
      "market\n",
      "astraea\n",
      "grammarbased\n",
      "fairness\n",
      "testing\n",
      "fairmixrep\n",
      "selfsupervised\n",
      "robust\n",
      "representation\n",
      "learning\n",
      "heterogeneous\n",
      "data\n",
      "fairness\n",
      "constraint\n",
      "banditbased\n",
      "algorithm\n",
      "fairnessaware\n",
      "hyperparameter\n",
      "optimization\n",
      "assessing\n",
      "fairness\n",
      "classifier\n",
      "collider\n",
      "bias\n",
      "metric\n",
      "method\n",
      "systematic\n",
      "comparison\n",
      "fairnessaware\n",
      "machine\n",
      "learning\n",
      "algorithm\n",
      "cryptocredit\n",
      "securely\n",
      "training\n",
      "fair\n",
      "model\n",
      "fairness\n",
      "perception\n",
      "networkcentric\n",
      "perspective\n",
      "fairn\n",
      "fair\n",
      "robust\n",
      "neural\n",
      "network\n",
      "structured\n",
      "data\n",
      "fairness\n",
      "causal\n",
      "algorithmic\n",
      "recourse\n",
      "equitable\n",
      "allocation\n",
      "healthcare\n",
      "resource\n",
      "fair\n",
      "cox\n",
      "model\n",
      "representativity\n",
      "fairness\n",
      "clustering\n",
      "exchanging\n",
      "lesson\n",
      "algorithmic\n",
      "fairness\n",
      "domain\n",
      "generalization\n",
      "explainability\n",
      "fair\n",
      "machine\n",
      "learning\n",
      "model\n",
      "reconstruction\n",
      "model\n",
      "explanation\n",
      "actionable\n",
      "recourse\n",
      "linear\n",
      "classification\n",
      "efficient\n",
      "search\n",
      "diverse\n",
      "coherent\n",
      "explanation\n",
      "human\n",
      "prediction\n",
      "explanation\n",
      "prediction\n",
      "machine\n",
      "learning\n",
      "model\n",
      "case\n",
      "study\n",
      "deception\n",
      "detection\n",
      "problem\n",
      "formulation\n",
      "fairness\n",
      "year\n",
      "test\n",
      "unfairness\n",
      "lesson\n",
      "machine\n",
      "learning\n",
      "fairness\n",
      "abstraction\n",
      "sociotechnical\n",
      "system\n",
      "clear\n",
      "sanction\n",
      "vague\n",
      "reward\n",
      "china\n",
      "social\n",
      "credit\n",
      "system\n",
      "currently\n",
      "defines\n",
      "good\n",
      "bad\n",
      "behavior\n",
      "taxonomy\n",
      "ethical\n",
      "tension\n",
      "inferring\n",
      "mental\n",
      "health\n",
      "state\n",
      "social\n",
      "medium\n",
      "dissecting\n",
      "racial\n",
      "bias\n",
      "algorithm\n",
      "guide\n",
      "health\n",
      "decision\n",
      "million\n",
      "people\n",
      "disparate\n",
      "interaction\n",
      "algorithmintheloop\n",
      "analysis\n",
      "fairness\n",
      "risk\n",
      "assessment\n",
      "empirical\n",
      "study\n",
      "rich\n",
      "subgroup\n",
      "fairness\n",
      "machine\n",
      "learning\n",
      "profiling\n",
      "potential\n",
      "computer\n",
      "vision\n",
      "challenge\n",
      "computational\n",
      "empiricism\n",
      "bias\n",
      "bios\n",
      "case\n",
      "study\n",
      "semantic\n",
      "representation\n",
      "bias\n",
      "highstakes\n",
      "setting\n",
      "equality\n",
      "voice\n",
      "towards\n",
      "fair\n",
      "representation\n",
      "crowdsourced\n",
      "topk\n",
      "recommendation\n",
      "analyzing\n",
      "bias\n",
      "perception\n",
      "truth\n",
      "news\n",
      "story\n",
      "implication\n",
      "fact\n",
      "checking\n",
      "microtargeting\n",
      "socially\n",
      "divisive\n",
      "ad\n",
      "case\n",
      "study\n",
      "russialinked\n",
      "ad\n",
      "campaign\n",
      "facebook\n",
      "siren\n",
      "simulation\n",
      "framework\n",
      "understanding\n",
      "effect\n",
      "recommender\n",
      "system\n",
      "online\n",
      "news\n",
      "environment\n",
      "controlling\n",
      "polarization\n",
      "personalization\n",
      "algorithmic\n",
      "framework\n",
      "fair\n",
      "algorithm\n",
      "learning\n",
      "allocation\n",
      "problem\n",
      "fair\n",
      "allocation\n",
      "competitive\n",
      "equilibrium\n",
      "generic\n",
      "income\n",
      "moral\n",
      "framework\n",
      "understanding\n",
      "fair\n",
      "ml\n",
      "economic\n",
      "model\n",
      "equality\n",
      "opportunity\n",
      "beyond\n",
      "open\n",
      "v\n",
      "closed\n",
      "balancing\n",
      "individual\n",
      "privacy\n",
      "public\n",
      "accountability\n",
      "data\n",
      "sharing\n",
      "who\n",
      "guinea\n",
      "pig\n",
      "investigating\n",
      "online\n",
      "abn\n",
      "test\n",
      "inthewild\n",
      "fairnessaware\n",
      "programming\n",
      "model\n",
      "card\n",
      "model\n",
      "reporting\n",
      "social\n",
      "cost\n",
      "strategic\n",
      "classification\n",
      "downstream\n",
      "effect\n",
      "affirmative\n",
      "action\n",
      "access\n",
      "populationlevel\n",
      "signaling\n",
      "source\n",
      "inequality\n",
      "disparate\n",
      "effect\n",
      "strategic\n",
      "manipulation\n",
      "account\n",
      "accounting\n",
      "algorithm\n",
      "systematic\n",
      "literature\n",
      "review\n",
      "algorithmic\n",
      "accountability\n",
      "algorithmic\n",
      "realism\n",
      "expanding\n",
      "boundary\n",
      "algorithmic\n",
      "thought\n",
      "algorithmic\n",
      "accountability\n",
      "public\n",
      "administration\n",
      "gdpr\n",
      "paradox\n",
      "closing\n",
      "ai\n",
      "accountability\n",
      "gap\n",
      "defining\n",
      "endtoend\n",
      "framework\n",
      "internal\n",
      "algorithmic\n",
      "auditing\n",
      "toward\n",
      "situated\n",
      "intervention\n",
      "algorithmic\n",
      "equity\n",
      "lesson\n",
      "field\n",
      "explainability\n",
      "fact\n",
      "sheet\n",
      "framework\n",
      "systematic\n",
      "assessment\n",
      "explainable\n",
      "approach\n",
      "multilayered\n",
      "explanation\n",
      "algorithmic\n",
      "impact\n",
      "assessment\n",
      "gdpr\n",
      "hidden\n",
      "assumption\n",
      "behind\n",
      "counterfactual\n",
      "explanation\n",
      "principal\n",
      "reason\n",
      "model\n",
      "fail\n",
      "contrastive\n",
      "local\n",
      "explanation\n",
      "retail\n",
      "forecasting\n",
      "human\n",
      "body\n",
      "black\n",
      "box\n",
      "supporting\n",
      "clinical\n",
      "decisionmaking\n",
      "deep\n",
      "learning\n",
      "assessing\n",
      "algorithmic\n",
      "fairness\n",
      "unobserved\n",
      "protected\n",
      "class\n",
      "using\n",
      "data\n",
      "combination\n",
      "fliptest\n",
      "fairness\n",
      "testing\n",
      "via\n",
      "optimal\n",
      "transport\n",
      "implication\n",
      "ai\n",
      "unfairness\n",
      "higher\n",
      "education\n",
      "admission\n",
      "effect\n",
      "perceived\n",
      "ai\n",
      "unfairness\n",
      "exit\n",
      "voice\n",
      "organizational\n",
      "reputation\n",
      "auditing\n",
      "radicalization\n",
      "pathway\n",
      "youtube\n",
      "case\n",
      "study\n",
      "predictive\n",
      "fairness\n",
      "reduce\n",
      "misdemeanor\n",
      "recidivism\n",
      "social\n",
      "service\n",
      "intervention\n",
      "concept\n",
      "fairness\n",
      "gdpr\n",
      "linguistic\n",
      "contextual\n",
      "interpretation\n",
      "concept\n",
      "fairness\n",
      "gdpr\n",
      "linguistic\n",
      "contextual\n",
      "interpretation\n",
      "pot\n",
      "protective\n",
      "optimization\n",
      "technology\n",
      "fair\n",
      "decision\n",
      "making\n",
      "using\n",
      "privacyprotected\n",
      "data\n",
      "fairness\n",
      "warning\n",
      "fairmaml\n",
      "learning\n",
      "fairly\n",
      "minimal\n",
      "data\n",
      "fairness\n",
      "warning\n",
      "fairmaml\n",
      "learning\n",
      "fairly\n",
      "minimal\n",
      "data\n",
      "fairness\n",
      "warning\n",
      "fairmaml\n",
      "learning\n",
      "fairly\n",
      "minimal\n",
      "data\n",
      "whose\n",
      "side\n",
      "ethic\n",
      "code\n",
      "power\n",
      "responsibility\n",
      "social\n",
      "good\n",
      "algorithmic\n",
      "targeting\n",
      "social\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "policy\n",
      "fairness\n",
      "accuracy\n",
      "distributed\n",
      "governance\n",
      "role\n",
      "computing\n",
      "social\n",
      "change\n",
      "role\n",
      "computing\n",
      "social\n",
      "change\n",
      "relationship\n",
      "trust\n",
      "ai\n",
      "trustworthy\n",
      "machine\n",
      "learning\n",
      "technology\n",
      "philosophical\n",
      "basis\n",
      "algorithmic\n",
      "recourse\n",
      "philosophical\n",
      "basis\n",
      "algorithmic\n",
      "recourse\n",
      "effect\n",
      "confidence\n",
      "explanation\n",
      "accuracy\n",
      "trust\n",
      "calibration\n",
      "aiassisted\n",
      "decision\n",
      "making\n",
      "leaveoneout\n",
      "unfairness\n",
      "fairness\n",
      "welfare\n",
      "equity\n",
      "personalized\n",
      "pricing\n",
      "reimagining\n",
      "algorithmic\n",
      "fairness\n",
      "india\n",
      "beyond\n",
      "narrative\n",
      "counternarratives\n",
      "data\n",
      "sharing\n",
      "africa\n",
      "whole\n",
      "thing\n",
      "smack\n",
      "gender\n",
      "algorithmic\n",
      "exclusion\n",
      "bioimpedancebased\n",
      "body\n",
      "composition\n",
      "analysis\n",
      "algorithmic\n",
      "recourse\n",
      "counterfactual\n",
      "explanation\n",
      "intervention\n",
      "semioticsbased\n",
      "epistemic\n",
      "tool\n",
      "reason\n",
      "ethical\n",
      "issue\n",
      "digital\n",
      "technology\n",
      "design\n",
      "development\n",
      "measurement\n",
      "fairness\n",
      "fairness\n",
      "risk\n",
      "assessment\n",
      "instrument\n",
      "postprocessing\n",
      "achieve\n",
      "counterfactual\n",
      "equalized\n",
      "odds\n",
      "high\n",
      "dimensional\n",
      "model\n",
      "explanation\n",
      "axiomatic\n",
      "approach\n",
      "agentbased\n",
      "model\n",
      "evaluate\n",
      "intervention\n",
      "online\n",
      "dating\n",
      "platform\n",
      "decrease\n",
      "racial\n",
      "homogamy\n",
      "designing\n",
      "accountable\n",
      "system\n",
      "socially\n",
      "fair\n",
      "kmeans\n",
      "clustering\n",
      "towards\n",
      "crosslingual\n",
      "generalization\n",
      "translation\n",
      "gender\n",
      "bias\n",
      "pilot\n",
      "study\n",
      "surveying\n",
      "clinical\n",
      "judgment\n",
      "evaluate\n",
      "radiology\n",
      "report\n",
      "generation\n",
      "fairness\n",
      "robustness\n",
      "investigating\n",
      "robustness\n",
      "disparity\n",
      "deep\n",
      "learning\n",
      "operationalizing\n",
      "framing\n",
      "support\n",
      "multiperspective\n",
      "recommendation\n",
      "opinion\n",
      "piece\n",
      "bridging\n",
      "machine\n",
      "learning\n",
      "mechanism\n",
      "design\n",
      "towards\n",
      "algorithmic\n",
      "fairness\n",
      "fair\n",
      "clustering\n",
      "via\n",
      "equitable\n",
      "group\n",
      "representation\n",
      "cant\n",
      "sit\n",
      "u\n",
      "exclusionary\n",
      "pedagogy\n",
      "ai\n",
      "ethic\n",
      "education\n",
      "fair\n",
      "classification\n",
      "groupdependent\n",
      "label\n",
      "noise\n",
      "censorship\n",
      "online\n",
      "encyclopedia\n",
      "implication\n",
      "nlp\n",
      "model\n",
      "impossible\n",
      "explanation\n",
      "beyond\n",
      "explainable\n",
      "ai\n",
      "gdpr\n",
      "covid\n",
      "use\n",
      "case\n",
      "scenario\n",
      "towards\n",
      "accountability\n",
      "machine\n",
      "learning\n",
      "datasets\n",
      "practice\n",
      "software\n",
      "engineering\n",
      "infrastructure\n",
      "fairness\n",
      "equality\n",
      "power\n",
      "algorithmic\n",
      "decisionmaking\n",
      "one\n",
      "label\n",
      "one\n",
      "billion\n",
      "face\n",
      "usage\n",
      "consistency\n",
      "racial\n",
      "category\n",
      "computer\n",
      "vision\n",
      "reviewable\n",
      "automated\n",
      "decisionmaking\n",
      "framework\n",
      "accountable\n",
      "algorithmic\n",
      "system\n",
      "danger\n",
      "stochastic\n",
      "parrot\n",
      "can\n",
      "language\n",
      "model\n",
      "big\n",
      "\n",
      "formalizing\n",
      "trust\n",
      "artificial\n",
      "intelligence\n",
      "prerequisite\n",
      "cause\n",
      "goal\n",
      "human\n",
      "trust\n",
      "ai\n",
      "tilt\n",
      "gdpraligned\n",
      "transparency\n",
      "information\n",
      "language\n",
      "toolkit\n",
      "practical\n",
      "privacy\n",
      "engineering\n"
     ]
    }
   ],
   "source": [
    "lemmatize_text(data['title_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#test_1 = data['title_tokens'].apply(lambda row: list(lem.lemmatize(row)))\n",
    "#test_2 = data['title_tokens'].apply(lambda row: lem.lemmatize(row))\n",
    "\n",
    "#need to amke this not a list somehow. \n",
    "# getting the error: \"TypeError: unhashable type: 'list'\"\n",
    "# if the column/list i'm passing isn't hashable then it's immutable\n",
    "#if it's immutable then it can't be manipulated. I.e. I can't lemmatize it. \n",
    "#So I need to make it unimmutable, I need to make it hashable\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Cleaning and Normalization:\n",
    "\n",
    "- check for nulls and decide what to do with them\n",
    "- whitespace\n",
    "- get rid of punctuations for the lists we created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modeling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of Dictionary, Corpus and Document Term Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA - Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CorEX - Correlation Explanation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
